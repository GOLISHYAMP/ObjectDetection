{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-16T11:06:50.274180Z","iopub.execute_input":"2025-01-16T11:06:50.274439Z","iopub.status.idle":"2025-01-16T11:06:50.278975Z","shell.execute_reply.started":"2025-01-16T11:06:50.274416Z","shell.execute_reply":"2025-01-16T11:06:50.277597Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"Followed this repo\nhttps://github.com/krishnaik06/TFOD/blob/main/object_detection_camera.ipynb","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nprint(tf.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T11:06:50.280231Z","iopub.execute_input":"2025-01-16T11:06:50.280578Z","iopub.status.idle":"2025-01-16T11:06:50.305873Z","shell.execute_reply.started":"2025-01-16T11:06:50.280546Z","shell.execute_reply":"2025-01-16T11:06:50.304620Z"}},"outputs":[{"name":"stdout","text":"2.17.1\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"Create the data directory\nThe snippet shown below will create the data directory where all our data will be stored. The code will create a directory structure as shown bellow:\n\n.. code-block:: bash\n\ndata\n└── models\nwhere the models folder will will contain the downloaded models.","metadata":{}},{"cell_type":"code","source":"import os\n\nDATA_DIR = os.path.join(os.getcwd(), 'data')\nMODELS_DIR = os.path.join(DATA_DIR, 'models')\nfor dir in [DATA_DIR, MODELS_DIR]:\n    if not os.path.exists(dir):\n        os.mkdir(dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T11:07:17.725811Z","iopub.execute_input":"2025-01-16T11:07:17.726155Z","iopub.status.idle":"2025-01-16T11:07:17.732022Z","shell.execute_reply.started":"2025-01-16T11:07:17.726131Z","shell.execute_reply":"2025-01-16T11:07:17.730877Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Download the model\nThe code snippet shown below is used to download the object detection model checkpoint file, as well as the labels file (.pbtxt) which contains a list of strings used to add the correct label to each detection (e.g. person).\n\nThe particular detection algorithm we will use is the SSD ResNet101 V1 FPN 640x640. More models can be found in the TensorFlow 2 Detection Model Zoo <https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md>_. To use a different model you will need the URL name of the specific model. This can be done as follows:\n\nRight click on the Model name of the model you would like to use;\nClick on Copy link address to copy the download link of the model;\nPaste the link in a text editor of your choice. You should observe a link similar to [download.tensorflow.org/models/object_detection/tf2/YYYYYYYY/XXXXXXXXX.tar.gz](http://);\nCopy the XXXXXXXXX part of the link and use it to replace the value of the MODEL_NAME variable in the code shown below;\nCopy the YYYYYYYY part of the link and use it to replace the value of the MODEL_DATE variable in the code shown below.\nFor example, the download link for the model used below is: [download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz](http://)","metadata":{}},{"cell_type":"code","source":"import tarfile\nimport urllib.request\n\n# Download and extract model\nMODEL_DATE = '20200711'\nMODEL_NAME = 'ssd_mobilenet_v2_320x320_coco17_tpu-8'\nMODEL_TAR_FILENAME = MODEL_NAME + '.tar.gz'\nMODELS_DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/tf2/'\nMODEL_DOWNLOAD_LINK = MODELS_DOWNLOAD_BASE + MODEL_DATE + '/' + MODEL_TAR_FILENAME\nPATH_TO_MODEL_TAR = os.path.join(MODELS_DIR, MODEL_TAR_FILENAME)\nPATH_TO_CKPT = os.path.join(MODELS_DIR, os.path.join(MODEL_NAME, 'checkpoint/'))\nPATH_TO_CFG = os.path.join(MODELS_DIR, os.path.join(MODEL_NAME, 'pipeline.config'))\nif not os.path.exists(PATH_TO_CKPT):\n    print('Downloading model. This may take a while... ', end='')\n    urllib.request.urlretrieve(MODEL_DOWNLOAD_LINK, PATH_TO_MODEL_TAR)\n    tar_file = tarfile.open(PATH_TO_MODEL_TAR)\n    tar_file.extractall(MODELS_DIR)\n    tar_file.close()\n    os.remove(PATH_TO_MODEL_TAR)\n    print('Done')\n\n# Download labels file\nLABEL_FILENAME = 'mscoco_label_map.pbtxt'\nLABELS_DOWNLOAD_BASE = \\\n    'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/data/'\nPATH_TO_LABELS = os.path.join(MODELS_DIR, os.path.join(MODEL_NAME, LABEL_FILENAME))\nif not os.path.exists(PATH_TO_LABELS):\n    print('Downloading label file... ', end='')\n    urllib.request.urlretrieve(LABELS_DOWNLOAD_BASE + LABEL_FILENAME, PATH_TO_LABELS)\n    print('Done')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T11:11:39.614130Z","iopub.execute_input":"2025-01-16T11:11:39.614594Z","iopub.status.idle":"2025-01-16T11:11:40.894820Z","shell.execute_reply.started":"2025-01-16T11:11:39.614561Z","shell.execute_reply":"2025-01-16T11:11:40.893592Z"}},"outputs":[{"name":"stdout","text":"Downloading model. This may take a while... Done\nDownloading label file... Done\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# Load the model\nNext we load the downloaded model","metadata":{}},{"cell_type":"code","source":"os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging\nimport tensorflow as tf\nfrom object_detection.utils import label_map_util\nfrom object_detection.utils import config_util\nfrom object_detection.utils import visualization_utils as viz_utils\nfrom object_detection.builders import model_builder\n\ntf.get_logger().setLevel('ERROR')           # Suppress TensorFlow logging (2)\n\n# Enable GPU dynamic memory allocation\ngpus = tf.config.experimental.list_physical_devices('GPU')\nfor gpu in gpus:\n    tf.config.experimental.set_memory_growth(gpu, True)\n\n# Load pipeline config and build a detection model\nconfigs = config_util.get_configs_from_pipeline_file(PATH_TO_CFG)\nmodel_config = configs['model']\ndetection_model = model_builder.build(model_config=model_config, is_training=False)\n\n# Restore checkpoint\nckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\nckpt.restore(os.path.join(PATH_TO_CKPT, 'ckpt-0')).expect_partial()\n\n@tf.function\ndef detect_fn(image):\n    \"\"\"Detect objects in image.\"\"\"\n\n    image, shapes = detection_model.preprocess(image)\n    prediction_dict = detection_model.predict(image, shapes)\n    detections = detection_model.postprocess(prediction_dict, shapes)\n\n    return detections, prediction_dict, tf.reshape(shapes, [-1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T11:13:31.724096Z","iopub.execute_input":"2025-01-16T11:13:31.724589Z","iopub.status.idle":"2025-01-16T11:13:32.177862Z","shell.execute_reply.started":"2025-01-16T11:13:31.724558Z","shell.execute_reply":"2025-01-16T11:13:32.176165Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-f2b20960f7fd>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TF_CPP_MIN_LOG_LEVEL'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'2'\u001b[0m    \u001b[0;31m# Suppress TensorFlow logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlabel_map_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvisualization_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mviz_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'object_detection'"],"ename":"ModuleNotFoundError","evalue":"No module named 'object_detection'","output_type":"error"}],"execution_count":6},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}